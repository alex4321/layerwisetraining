{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import transformers\n",
    "import datasets\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import IterableDataset\n",
    "import math\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = os.environ[\"HF_TOKEN\"]\n",
    "BASE_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "DATASET_PATH = \"G:/data/layerwisetraining\"\n",
    "BF16 = torch.cuda.is_bf16_supported()\n",
    "DTYPE = torch.bfloat16 if BF16 else torch.float16\n",
    "DEVICE = \"cuda:0\"\n",
    "DEVICE_ORIGINAL_MODEL = \"cpu\"\n",
    "CHECKPOINT_PATH = \"F:/layerwisetraining\"\n",
    "LOG_DIR = \"F:/layerwisetraining/tensorboard\"\n",
    "RANDOM_SEED = 20250330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1801350\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"Salesforce/wikitext\", \"wikitext-103-raw-v1\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    token=HF_TOKEN,\n",
    "    torch_dtype=DTYPE,\n",
    "    device_map=DEVICE_ORIGINAL_MODEL,\n",
    "    attn_implementation=\"eager\",\n",
    ")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    token=HF_TOKEN,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_layers = [\n",
    "    layer\n",
    "    for layer in base_model.model.layers\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_embeddings_dataset(ds, tokenizer, directory, chunk_size):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    texts = ds['text']\n",
    "    chunk_count = int(math.ceil(\n",
    "        len(texts) / chunk_size\n",
    "    ))\n",
    "    for i in tqdm(range(chunk_count)):\n",
    "        fname = os.path.join(directory, f\"chunk-{i}.pkl\")\n",
    "        if os.path.exists(fname):\n",
    "            continue\n",
    "        chunk_texts = texts[i * chunk_size : (i + 1) * chunk_size]\n",
    "        chunk_batches = {}\n",
    "        for j, text in enumerate(chunk_texts):\n",
    "            global_index = i * chunk_size + j\n",
    "            batch = tokenizer(text, return_tensors=\"pt\")\n",
    "            batch[\"labels\"] = batch[\"input_ids\"]\n",
    "            batch[\"inputs_embeds\"] = base_model.model.embed_tokens(batch[\"input_ids\"])\n",
    "            del batch[\"input_ids\"]\n",
    "            batch_flatten = {\n",
    "                key: value[0]\n",
    "                for key, value in batch.items()\n",
    "            }\n",
    "            chunk_batches[global_index] = batch_flatten\n",
    "        with open(fname, \"wb\") as f:\n",
    "            pickle.dump(chunk_batches, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_to_embeddings_dataset(\n",
    "    ds['test'].filter(lambda x: len(x['text']) > 100).shuffle(seed=RANDOM_SEED),\n",
    "    tokenizer,\n",
    "    os.path.join(DATASET_PATH, \"test-layer-0-inputs\"),\n",
    "    chunk_size=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:00<00:00, 61336.97it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_to_embeddings_dataset(\n",
    "    ds['train'].filter(lambda x: len(x['text']) > 100).shuffle(seed=RANDOM_SEED),\n",
    "    tokenizer,\n",
    "    os.path.join(DATASET_PATH, \"train-layer-0-inputs\"),\n",
    "    chunk_size=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsDataset(IterableDataset):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "        self.chunk_size, self.total_size = self._get_sizes()\n",
    "\n",
    "    def _read(self, fname):\n",
    "        with open(os.path.join(self.dirname, fname), 'rb') as src:\n",
    "            return pickle.load(src)\n",
    "    \n",
    "    def _get_sizes(self):\n",
    "        chunk_size = len(self._read('chunk-0.pkl'))\n",
    "        chunk_files = [\n",
    "            fname\n",
    "            for fname in os.listdir(self.dirname)\n",
    "            if fname.startswith(\"chunk\") and fname.endswith(\".pkl\")\n",
    "        ]\n",
    "        chunk_count = len(chunk_files)\n",
    "        last_chunk_size = len(self._read(f'chunk-{chunk_count-1}.pkl'))\n",
    "        return chunk_size, chunk_size * (chunk_count - 1) + last_chunk_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        chunk_count = int(math.ceil(self.total_size / self.chunk_size))\n",
    "        for i in range(chunk_count):\n",
    "            chunk_data = self._read(f'chunk-{i}.pkl')\n",
    "            for value in chunk_data.values():\n",
    "                yield value\n",
    "\n",
    "\n",
    "def get_embeddings_dataset(dirname):\n",
    "    return EmbeddingsDataset(dirname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    with torch.no_grad():\n",
    "        # Get shapes\n",
    "        max_len = max(item['inputs_embeds'].shape[0] for item in batch)\n",
    "        batch_size = len(batch)\n",
    "        hidden_size = batch[0]['inputs_embeds'].shape[1]\n",
    "        \n",
    "        # Initialize padded tensors\n",
    "        padded_input_embeds = torch.rand((batch_size, max_len, hidden_size), dtype=DTYPE)\n",
    "        padded_attention_mask = torch.zeros((batch_size, max_len))\n",
    "        padded_labels = torch.full((batch_size, max_len), fill_value=-100)\n",
    "        \n",
    "        # Fill padded tensors with actual values\n",
    "        for i, item in enumerate(batch):\n",
    "            seq_len = item['inputs_embeds'].shape[0]\n",
    "            padded_input_embeds[i, :seq_len] = item['inputs_embeds']\n",
    "            padded_attention_mask[i, :seq_len] = item['attention_mask']\n",
    "            padded_labels[i, :seq_len] = item['labels']\n",
    "            \n",
    "        return {\n",
    "            'inputs_embeds': padded_input_embeds,\n",
    "            'attention_mask': padded_attention_mask,\n",
    "            'labels': padded_labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_layer_model(base_model, attention_implementation):\n",
    "    config = copy.deepcopy(base_model.config)\n",
    "    config.num_hidden_layers = 1\n",
    "    config._attn_implementation_autoset = False\n",
    "    config._attn_implementation = attention_implementation\n",
    "    config.rms_norm_eps = 1e-5\n",
    "    model = transformers.LlamaForCausalLM(config).to(\n",
    "        dtype=DTYPE\n",
    "    ).to(\n",
    "        device=DEVICE\n",
    "    )\n",
    "    for original_module, new_module in [\n",
    "        (base_model.model.embed_tokens, model.model.embed_tokens),\n",
    "        (base_model.model.norm, model.model.norm),\n",
    "        (base_model.model.rotary_emb, model.model.rotary_emb),\n",
    "        (base_model.lm_head, model.lm_head),\n",
    "    ]:\n",
    "        new_module.load_state_dict(original_module.state_dict())\n",
    "    for freeze_module in [model.model.embed_tokens, model.model.norm, model.model.rotary_emb, model.lm_head]:\n",
    "        for param in freeze_module.parameters():\n",
    "            param.requires_grad = False\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6\n",
    "GRADIENT_ACCUMULATION_STEPS = 20\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_STEPS = 500\n",
    "SAVE_LIMIT = 3\n",
    "WARMUP_STEPS = 500\n",
    "MAX_GRAD_NORN = 1.0\n",
    "RANDOM_SEED = 42\n",
    "EARLY_STOPPING_PATIENCE = 1\n",
    "GRADIENT_NORM_LOGGING_FREQUENCY = 20\n",
    "#MAX_STEPS = 6000\n",
    "MAX_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "ds_embeddings_train = get_embeddings_dataset(\n",
    "    os.path.join(DATASET_PATH, f\"train-layer-{layer_idx}-inputs\")\n",
    ")\n",
    "ds_embeddings_train = get_embeddings_dataset(\n",
    "    os.path.join(DATASET_PATH, f\"test-layer-{layer_idx}-inputs\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "ds_embeddings_train = get_embeddings_dataset(\n",
    "    os.path.join(DATASET_PATH, f\"train-layer-{layer_idx}-inputs\")\n",
    ")\n",
    "ds_embeddings_test = get_embeddings_dataset(\n",
    "    os.path.join(DATASET_PATH, f\"test-layer-{layer_idx}-inputs\")\n",
    ")\n",
    "train_checkpoint_path = os.path.join(CHECKPOINT_PATH, f\"layer-{layer_idx}-train-checkpoints\")\n",
    "train_logging_path = os.path.join(CHECKPOINT_PATH, f\"layer-{layer_idx}-train-logs\")\n",
    "train_model = create_one_layer_model(base_model, \"eager\") # Flash Attention 2 returns NaN gradients\n",
    "train_model.model.layers[0].load_state_dict(base_model.model.layers[layer_idx].state_dict()) # Load layer 0 to one-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    ds_embeddings_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    ds_embeddings_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WARMUP_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6247"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(MAX_EPOCHS * len(train_dataloader)) // GRADIENT_ACCUMULATION_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    train_model.parameters(),\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=WARMUP_STEPS,\n",
    "    num_training_steps=(MAX_EPOCHS * len(train_dataloader)) // GRADIENT_ACCUMULATION_STEPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = train_model.to(DEVICE).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, verbose=False):\n",
    "    model.eval()\n",
    "    loss_values = []\n",
    "    if verbose:\n",
    "        dataloader = tqdm(dataloader)\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {k: v.to(model.device) for k, v in batch.items()}\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            loss_values.append(loss.item())\n",
    "    return sum(loss_values) / len(loss_values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_model, train_dataloader, optimizer, lr_scheduler, logger):\n",
    "    step = 0\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        print(f\"EPOCH {epoch}\")\n",
    "        print(\"TRAINING\")\n",
    "        train_model.train()\n",
    "        for batch_idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "            if batch_idx % GRADIENT_ACCUMULATION_STEPS:\n",
    "                step += 1\n",
    "            inputs = {k: v.to(train_model.device) for k, v in batch.items()}\n",
    "            outputs = train_model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            (loss / GRADIENT_ACCUMULATION_STEPS).backward()\n",
    "            logger(\"loss\", step, loss.item())\n",
    "            global_step = (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS\n",
    "            if global_step == 0 or batch_idx == len(train_dataloader) - 1:\n",
    "                torch.nn.utils.clip_grad_norm_(train_model.parameters(), MAX_GRAD_NORN)\n",
    "                if global_step % GRADIENT_NORM_LOGGING_FREQUENCY == 0:\n",
    "                    with torch.no_grad():\n",
    "                        for name, param in train_model.named_parameters():\n",
    "                            if param.grad is not None:\n",
    "                                param_norm = param.grad.data.norm(2).item()\n",
    "                                logger(f\"grad_norm/{name}\", step, param_norm)\n",
    "                # Log the current learning rate\n",
    "                current_lr = lr_scheduler.get_last_lr()[0]\n",
    "                logger(\"learning_rate\", step, current_lr)\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                if step % SAVE_STEPS == 0:\n",
    "                    yield step\n",
    "                    train_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(train_model, optimizer, lr_scheduler, step):\n",
    "    os.makedirs(train_checkpoint_path, exist_ok=True)\n",
    "    previous_checkpoints = [\n",
    "        fname\n",
    "        for fname in os.listdir(train_checkpoint_path)\n",
    "        if fname.startswith(\"checkpoint\")\n",
    "    ]\n",
    "    previous_checkpoints_indices = [\n",
    "        int(checkpoint_fname.split(\"-\")[-1].replace(\".bin\", \"\"))\n",
    "        for checkpoint_fname in previous_checkpoints\n",
    "    ]\n",
    "    previous_checkpoints_data = sorted(\n",
    "        zip(previous_checkpoints, previous_checkpoints_indices),\n",
    "        key=lambda pair: pair[1]\n",
    "    )\n",
    "    if len(previous_checkpoints_data) > (SAVE_LIMIT - 1):\n",
    "        for fname, _ in previous_checkpoints_data[:-(SAVE_LIMIT - 1)]:\n",
    "            os.remove(os.path.join(train_checkpoint_path, fname))\n",
    "    checkpoint = {\n",
    "        'model_state_dict': train_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "        'step': step,\n",
    "    }\n",
    "    fname = os.path.join(train_checkpoint_path, f\"checkpoint-{step}.bin\")\n",
    "    torch.save(checkpoint, fname)\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 306/306 [00:22<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "TRAINING\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10366/124957 [51:26<3:04:28, 10.35it/s]   "
     ]
    }
   ],
   "source": [
    "log_dir = os.path.join(LOG_DIR, f\"layer-{layer_idx}\")\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "initial_loss = evaluate(train_model, test_dataloader, verbose=True)\n",
    "writer.add_scalar('eval/loss', initial_loss, 0)\n",
    "eval_without_improvement = 0\n",
    "best_loss = None\n",
    "for save_step in train(\n",
    "    train_model=train_model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    logger=lambda metric, step, loss: writer.add_scalar(f'train/{metric}', loss, step)\n",
    "):\n",
    "    loss = evaluate(train_model, test_dataloader, verbose=False)\n",
    "    writer.add_scalar('eval/loss', loss, save_step)\n",
    "    if (best_loss is None) or (loss < best_loss):\n",
    "        best_loss = loss\n",
    "        eval_without_improvement = 0\n",
    "    else:\n",
    "        eval_without_improvement += 1\n",
    "    if eval_without_improvement > EARLY_STOPPING_PATIENCE:\n",
    "        break\n",
    "    save_checkpoint(\n",
    "        train_model=train_model,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        step=save_step,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_next_layer_dataset(ds, model, path, chunk_size):\n",
    "    model.eval()\n",
    "    def _chunk_iterate():\n",
    "        chunk = {}\n",
    "        for i, item in enumerate(tqdm(ds)):\n",
    "            with torch.no_grad():\n",
    "                batch = {\n",
    "                    key: value.reshape([1] + list(value.shape)).to(model.device)\n",
    "                    for key, value in item.items()\n",
    "                }\n",
    "                output = model(**batch, output_hidden_states=True)\n",
    "                hidden_state = output.hidden_states[-1]\n",
    "                hidden_state = hidden_state.reshape(hidden_state.shape[1:])\n",
    "                item[\"inputs_embeds\"] = hidden_state.to(\"cpu\")\n",
    "                chunk[i] = item\n",
    "                if len(chunk) == chunk_size:\n",
    "                    yield chunk\n",
    "                    chunk = {}\n",
    "        if len(chunk) > 0:\n",
    "            yield chunk\n",
    "        \n",
    "    def _main():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        for i, chunk in enumerate(_chunk_iterate()):\n",
    "            full_path = os.path.join(path, f\"chunk-{i}.pkl\")\n",
    "            with open(full_path, \"wb\") as dst:\n",
    "                pickle.dump(chunk, dst)\n",
    "    \n",
    "    _main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_next_layer_dataset(\n",
    "    ds_embeddings_test,\n",
    "    train_model,\n",
    "    \"G:\\\\data\\\\layerwisetraining\\\\test-layer-1-inputs\",\n",
    "    1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_next_layer_dataset(\n",
    "    ds_embeddings_train,\n",
    "    train_model,\n",
    "    \"G:\\\\data\\\\layerwisetraining\\\\train-layer-1-inputs\",\n",
    "    1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
