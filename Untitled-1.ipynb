{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is written using Llama self attention module as example.\n",
    "\n",
    "### Original self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's denote\n",
    "\n",
    "- $B$ is batch size\n",
    "- $S$ is a sequence length\n",
    "- $D$ is a hidden size\n",
    "\n",
    "- and we have $X \\in \\mathbb{R}^{B, S, D}$ input.\n",
    "\n",
    "Let's denote parameters:\n",
    "- $W_Q \\in \\mathbb{R}^{D x (H d_h)}$ - query projection\n",
    "- $W_K \\in \\mathbb{R}^{D x (H d_h)}$ - key projection\n",
    "- $W_V \\in \\mathbb{R}^{D x (H d_h)}$ - value projection\n",
    "- $W_O \\in \\mathbb{R}^{D x (H d_h)}$ - output projection\n",
    "- where $H$ is head count and $d_h$ is individual head dimension\n",
    "- also, $H_k$ is a number of key-value heads\n",
    "\n",
    "Now let's write down query / key / value projections:\n",
    "\n",
    "- $Q = X W_Q, Q \\in \\mathbb{R}^{B x S x (H d_h)}$\n",
    "- $K = X W_K, K \\in \\mathbb{R}^{B x S x (H d_h)}$\n",
    "- $V = X W_V, V \\in \\mathbb{R}^{B x S x (H d_h)}$\n",
    "\n",
    "Now let's transpose them for multihead attention:\n",
    "- $Q_{transposed} = Q.view(B, S, H, d_h).transpose(1, 2), Q_{transposed} \\in \\mathbb{R}^{B x H x S x d_h}$\n",
    "- $K_{transposed} = K.view(B, S, H, d_h).transpose(1, 2), K_{transposed} \\in \\mathbb{R}^{B x H x S x d_h}$\n",
    "- $V_{transposed} = V.view(B, S, H, d_h).transpose(1, 2), V_{transposed} \\in \\mathbb{R}^{B x H x S x d_h}$\n",
    "\n",
    "Now let's write down RoPE (rotary position embeddings)\n",
    "\n",
    "- $rotateHalf(X) = (-X_{:, :, :, d_h/2:}, X_{:, :, :, :d_h/2})$\n",
    "- $Q_{rotated} = Q_{transposed} cos(\\theta) + rotateHalf(Q_{transposed}) sin(\\theta)$\n",
    "- $K_{rotated} = K_{transposed} cos(\\theta) + rotateHalf(K_{transposed}) sin(\\theta)$\n",
    "\n",
    "```python\n",
    "def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
    "    \"\"\"Applies Rotary Position Embedding to the query and key tensors.\n",
    "\n",
    "    Args:\n",
    "        q (`torch.Tensor`): The query tensor.\n",
    "        k (`torch.Tensor`): The key tensor.\n",
    "        cos (`torch.Tensor`): The cosine part of the rotary embedding.\n",
    "        sin (`torch.Tensor`): The sine part of the rotary embedding.\n",
    "        position_ids (`torch.Tensor`, *optional*):\n",
    "            Deprecated and unused.\n",
    "        unsqueeze_dim (`int`, *optional*, defaults to 1):\n",
    "            The 'unsqueeze_dim' argument specifies the dimension along which to unsqueeze cos[position_ids] and\n",
    "            sin[position_ids] so that they can be properly broadcasted to the dimensions of q and k. For example, note\n",
    "            that cos[position_ids] and sin[position_ids] have the shape [batch_size, seq_len, head_dim]. Then, if q and\n",
    "            k have the shape [batch_size, heads, seq_len, head_dim], then setting unsqueeze_dim=1 makes\n",
    "            cos[position_ids] and sin[position_ids] broadcastable to the shapes of q and k. Similarly, if q and k have\n",
    "            the shape [batch_size, seq_len, heads, head_dim], then set unsqueeze_dim=2.\n",
    "    Returns:\n",
    "        `tuple(torch.Tensor)` comprising of the query and key tensors rotated using the Rotary Position Embedding.\n",
    "    \"\"\"\n",
    "    cos = cos.unsqueeze(unsqueeze_dim)\n",
    "    sin = sin.unsqueeze(unsqueeze_dim)\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_embed, k_embed\n",
    "```\n",
    "\n",
    "\n",
    "Assuming $H=H_k$ no repeat occurs, so attention directly use $Q_{rotated}$ and $K_{rotated}$\n",
    "\n",
    "Now to attention scores:\n",
    "\n",
    "- $A = { {Q_{rotated} K_{rotated}^T} \\over {\\sqrt{d_h}} } + M$, where $M$ is a causal mask with large negative values for masked positions\n",
    "- Now applying softmax and dropout:\n",
    "\n",
    "  $ A_{postprocessed} = dropout(softmax(A, dim=-1), p)$ where we can do dropout through elemenwise multiplication to random matrix.\n",
    "\n",
    "  So $ A_{postprocessed} = softmax(A, dim=-1) * (random(S, S) < p)$\n",
    "\n",
    "Weighted sum:\n",
    "\n",
    "- $O = A_{postprocessed} V = A_{postprocessed} (X W_V)$\n",
    "- $O_{reshaped} = O.view((B, S, D))$\n",
    "\n",
    "Than final output is \n",
    "\n",
    "$Y = O_{reshaped} W_O$\n",
    "\n",
    "### Attention simpliciation idea\n",
    "\n",
    "But we can (formally incorrectly, I am just checking if the idea will be a good approximation) to think about $A$ as a linear attention, this way replacing:\n",
    "\n",
    "- $A = { {Q_{rotated} K_{rotated}^T} \\over {\\sqrt{d_h}}}$\n",
    "- $A_{postprocessed} = A * (random(S, S) < p)$\n",
    "\n",
    "Now, assuming that all we know after attention computation is two matrices (but we know query / key / value projections other internal stuff, it is just attention mechanism what we don't want to recompute):\n",
    "- $A_{postprocessed}$ \n",
    "- $O$\n",
    "\n",
    "Now, assuming we used these replaced attention mechanism during forward pass.\n",
    "\n",
    "Assuming we have this loss function: $Loss(Y, X) = |Y_{:, :-1, :} - X_{:, 1:, :}|$ (expecting $Y$ and $X$ to be $(B, S, D)$ shape matrixes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Inputs\n",
    "B, S, D = X.shape\n",
    "X = torch.randn(1, 2, 2)  # (B, S, D)\n",
    "Y_target = X[:, 1:, :]     # Loss compares Y[:, :-1] to X[:, 1:]\n",
    "\n",
    "# Parameters\n",
    "W_Q = torch.randn(2, 2, requires_grad=True)\n",
    "W_K = torch.randn(2, 2, requires_grad=True)\n",
    "W_V = torch.randn(2, 2, requires_grad=True)\n",
    "W_O = torch.randn(2, 2, requires_grad=True)\n",
    "\n",
    "# Fixed dropout mask (for reproducibility)\n",
    "dropout_mask = (torch.rand(2, 2) > 0.5).float()  # Binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_half(x):\n",
    "    d = x.shape[-1]\n",
    "    return torch.cat((-x[..., d//2:], x[..., :d//2]), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, cos, sin):\n",
    "    q_rotated = q * cos + rotate_half(q) * sin\n",
    "    k_rotated = k * cos + rotate_half(k) * sin\n",
    "    return q_rotated, k_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotary_embeddings(seq_len: int, dim: int, theta: float = 10000.0):\n",
    "    position = torch.arange(seq_len, dtype=torch.float32)\n",
    "    freqs = theta ** (-2 * torch.arange(0, dim, 2).float() / dim)\n",
    "    angles = position.unsqueeze(1) * freqs.unsqueeze(0)  # (S, dim/2)\n",
    "    \n",
    "    cos = torch.cos(angles)  # (S, dim/2)\n",
    "    sin = torch.sin(angles)  # (S, dim/2)\n",
    "    \n",
    "    # Expand to match the shape of Q/K (B, H, S, d_h)\n",
    "    cos = cos.view(1, 1, seq_len, -1)  # (1, 1, S, d_h/2)\n",
    "    sin = sin.view(1, 1, seq_len, -1)\n",
    "    \n",
    "    # Concatenate to handle even/odd dimensions properly\n",
    "    cos = torch.cat([cos, cos], dim=-1)\n",
    "    sin = torch.cat([sin, sin], dim=-1)\n",
    "    return cos, sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for S=2, d_h=2\n",
    "cos, sin = get_rotary_embeddings(seq_len=2, dim=2, theta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "Q = torch.matmul(X, W_Q)  # (B, S, H*d_h)\n",
    "K = torch.matmul(X, W_K)\n",
    "V = torch.matmul(X, W_V)\n",
    "\n",
    "Q_transposed = Q.view(1, 2, 1, 2).transpose(1, 2)  # (B, H, S, d_h)\n",
    "K_transposed = K.view(1, 2, 1, 2).transpose(1, 2)\n",
    "V_transposed = V.view(1, 2, 1, 2).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply RoPE with precomputed cos/sin\n",
    "Q_rotated, K_rotated = apply_rotary_pos_emb(Q_transposed, K_transposed, cos, sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rest of forward pass remains the same...\n",
    "A = (torch.matmul(Q_rotated, K_rotated.transpose(-1, -2)) / (2**0.5))  # Scaled by sqrt(d_h)\n",
    "A_postprocessed = A * dropout_mask  # Apply dropout mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = torch.matmul(A_postprocessed, V_transposed)\n",
    "O_reshaped = O.transpose(1, 2).reshape(1, 2, 2)\n",
    "Y = torch.matmul(O_reshaped, W_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.abs(Y[:, :-1, :] - X[:, 1:, :]).sum()\n",
    "loss.backward()\n",
    "\n",
    "# Autograd gradients\n",
    "autograd_grad_W_O = W_O.grad.clone()\n",
    "autograd_grad_W_V = W_V.grad.clone()\n",
    "autograd_grad_W_K = W_K.grad.clone()\n",
    "autograd_grad_W_Q = W_Q.grad.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After forward pass:\n",
    "Q_rotated = Q_rotated.detach()\n",
    "K_rotated = K_rotated.detach()\n",
    "V_transposed = V_transposed.detach()\n",
    "A_postprocessed = A_postprocessed.detach()\n",
    "dropout_mask = dropout_mask.detach()\n",
    "cos = cos.detach()\n",
    "sin = sin.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dLoss_dY = torch.sign(Y[:, :-1, :] - X[:, 1:, :])  # Gradient of L1 loss\n",
    "manual_grad_W_O = torch.einsum('bsd,bse->de', O_reshaped[:, :-1, :], dLoss_dY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∇W_O match: True\n"
     ]
    }
   ],
   "source": [
    "print(\"∇W_O match:\", torch.allclose(autograd_grad_W_O, manual_grad_W_O, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dLoss_dY (gradient from Y[:, :-1, :])\n",
    "dLoss_dY = torch.sign(Y[:, :-1, :] - X[:, 1:, :])  # Shape: (1, 1, 2)\n",
    "\n",
    "# Expand to full sequence length with zeros\n",
    "dLoss_dY_full = torch.zeros_like(Y)                # Shape: (1, 2, 2)\n",
    "dLoss_dY_full[:, :-1, :] = dLoss_dY                # Fill first S-1 positions\n",
    "\n",
    "# Gradient for O_reshaped: dLoss_dY_full @ W_O^T\n",
    "dLoss_dO_reshaped = torch.matmul(dLoss_dY_full, W_O.T)  # Shape: (1, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and transpose to match O’s original shape (B, H, S, d_h) = (1, 1, 2, 2)\n",
    "dLoss_dO = dLoss_dO_reshaped.view(1, 2, 1, 2).transpose(1, 2)  # Shape: (1, 1, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.7708,  0.6129],\n",
       "          [ 0.0000,  0.0000]]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLoss_dO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∇W_V match: True\n"
     ]
    }
   ],
   "source": [
    "# Compute dLoss_dY_full (includes zeros for unused positions)\n",
    "dLoss_dY = torch.sign(Y[:, :-1, :] - X[:, 1:, :])  # (B, S-1, D) = (1, 1, 2)\n",
    "dLoss_dY_full = torch.zeros(1, 2, 2)               # (B, S, D) = (1, 2, 2)\n",
    "dLoss_dY_full[:, :-1, :] = dLoss_dY                # Fill valid positions\n",
    "\n",
    "# Compute dLoss_dO_reshaped = dLoss_dY_full @ W_O^T\n",
    "dLoss_dO_reshaped = torch.matmul(dLoss_dY_full, W_O.T)  # (1, 2, 2)\n",
    "\n",
    "# Reshape/transpose to match O’s shape (B, H, S, d_h) = (1, 1, 2, 2)\n",
    "dLoss_dO = dLoss_dO_reshaped.view(1, 2, 1, 2).transpose(1, 2)  # (1, 1, 2, 2)\n",
    "\n",
    "# Now compute dLoss/dV_transposed\n",
    "dLoss_dV_transposed = torch.matmul(A_postprocessed.transpose(-1, -2), dLoss_dO)  # (1, 1, 2, 2)\n",
    "dLoss_dV = dLoss_dV_transposed.transpose(1, 2).reshape(1, 2, 2)  # (1, 2, 2)\n",
    "\n",
    "# Manual gradient for W_V\n",
    "manual_grad_W_V = torch.einsum('bsd,bse->de', X, dLoss_dV)\n",
    "\n",
    "print(\"∇W_V match:\", torch.allclose(autograd_grad_W_V, manual_grad_W_V, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.7708,  0.6129],\n",
       "          [ 0.0000,  0.0000]]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLoss_dO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rotary_pos_emb_backward(grad_rotated, cos, sin):\n",
    "    # Gradient through RoPE for K\n",
    "    grad_transposed = grad_rotated * cos + rotate_half(grad_rotated) * sin\n",
    "    return grad_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∇W_Q match: True\n"
     ]
    }
   ],
   "source": [
    "# Incorrect line (extra division by sqrt(d_h)):\n",
    "# dLoss_dA = torch.matmul(dLoss_dO, V_transposed.transpose(-1, -2)) * dropout_mask / (2**0.5)\n",
    "\n",
    "# Corrected line (remove division by sqrt(d_h)):\n",
    "dLoss_dA = torch.matmul(dLoss_dO, V_transposed.transpose(-1, -2)) * dropout_mask  # Shape: (1, 1, 2, 2)\n",
    "\n",
    "# Backprop through A = Q_rotated @ K_rotated^T / sqrt(d_h)\n",
    "dLoss_dQ_rotated = torch.matmul(dLoss_dA, K_rotated) / (2**0.5)  # Apply scaling here\n",
    "\n",
    "# Backprop through RoPE for Q (correct sign)\n",
    "dLoss_dQ_transposed = dLoss_dQ_rotated * cos - rotate_half(dLoss_dQ_rotated) * sin\n",
    "\n",
    "# Reshape and compute dLoss/dW_Q\n",
    "dLoss_dQ = dLoss_dQ_transposed.transpose(1, 2).reshape(1, 2, 2)\n",
    "manual_grad_W_Q = torch.einsum('bsd,bse->de', X, dLoss_dQ)\n",
    "\n",
    "print(\"∇W_Q match:\", torch.allclose(autograd_grad_W_Q, manual_grad_W_Q, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∇W_K match: False\n"
     ]
    }
   ],
   "source": [
    "# Backprop through A = Q_rotated @ K_rotated^T / sqrt(d_h)\n",
    "dLoss_dK_rotated = torch.matmul(Q_rotated.transpose(-1, -2), dLoss_dA) / (2**0.5)  # Apply scaling here\n",
    "\n",
    "# Backprop through RoPE for K (FIXED SIGN HERE)\n",
    "dLoss_dK_transposed = dLoss_dK_rotated * cos - rotate_half(dLoss_dK_rotated) * sin  # \"-\" instead of \"+\"\n",
    "#dLoss_dK_transposed = apply_rotary_pos_emb_backward(dLoss_dK_rotated, cos, sin)\n",
    "\n",
    "# Reshape and compute dLoss/dW_K\n",
    "dLoss_dK = dLoss_dK_transposed.transpose(1, 2).reshape(1, 2, 2)\n",
    "manual_grad_W_K = torch.einsum('bsd,bse->de', X, dLoss_dK)\n",
    "\n",
    "print(\"∇W_K match:\", torch.allclose(autograd_grad_W_K, manual_grad_W_K, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0192,  0.0048],\n",
       "        [-0.0047, -0.0012]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autograd_grad_W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0158, -0.0219],\n",
       "        [-0.0039,  0.0152]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_grad_W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∇W_K match: False\n"
     ]
    }
   ],
   "source": [
    "B, S, D = X.shape\n",
    "H = 1\n",
    "d_h = 2\n",
    "# Step 1: Gradient from Loss to Y\n",
    "dLoss_dY = torch.sign(Y[:, :-1, :] - X[:, 1:, :])\n",
    "dLoss_dY_full = torch.zeros(B, S, D)\n",
    "dLoss_dY_full[:, :-1, :] = dLoss_dY\n",
    "\n",
    "# Step 2: Gradient from Y to O\n",
    "dLoss_dO_reshaped = torch.matmul(dLoss_dY_full, W_O.T)\n",
    "dLoss_dO = dLoss_dO_reshaped.view(B, S, H, d_h).transpose(1, 2)\n",
    "\n",
    "# Step 3: Gradient from O to A_postprocessed\n",
    "dLoss_dA = torch.matmul(dLoss_dO, V_transposed.transpose(-1, -2)) * dropout_mask\n",
    "\n",
    "# Step 4: Gradient from A to K_rotated\n",
    "dLoss_dK_rotated = torch.matmul(Q_rotated.transpose(-1, -2), dLoss_dA) / (d_h**0.5)\n",
    "\n",
    "# Step 5: Gradient through RoPE\n",
    "dLoss_dK_transposed = dLoss_dK_rotated * cos - rotate_half(dLoss_dK_rotated) * sin\n",
    "\n",
    "# Step 6: Gradient from K_transposed to K\n",
    "dLoss_dK = dLoss_dK_transposed.transpose(1, 2).reshape(B, S, H * d_h)\n",
    "\n",
    "# Step 7: Gradient from K to W_K\n",
    "manual_grad_W_K = torch.einsum('bsd,bse->de', X, dLoss_dK)\n",
    "\n",
    "# Verify\n",
    "print(\"∇W_K match:\", torch.allclose(W_K.grad, manual_grad_W_K, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0158, -0.0219],\n",
       "        [-0.0039,  0.0152]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_grad_W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0192,  0.0048],\n",
       "        [-0.0047, -0.0012]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_K.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0118, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(manual_grad_W_K - W_K.grad).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Gradient from Loss to Y\n",
    "dLoss_dY = torch.sign(Y[:, :-1, :] - X[:, 1:, :])\n",
    "dLoss_dY_full = torch.zeros_like(Y)\n",
    "dLoss_dY_full[:, :-1, :] = dLoss_dY\n",
    "\n",
    "# Step 2: Gradient from Y to O\n",
    "dLoss_dO_reshaped = torch.matmul(dLoss_dY_full, W_O.T.detach())\n",
    "dLoss_dO = dLoss_dO_reshaped.view(B, S, H, d_h).transpose(1, 2)\n",
    "\n",
    "# Step 3: Gradient from O to A_postprocessed\n",
    "dLoss_dA = torch.matmul(dLoss_dO, V_transposed.transpose(-1, -2)) * dropout_mask\n",
    "\n",
    "# Step 4: Gradient from A_postprocessed to K_rotated\n",
    "dLoss_dK_rotated = torch.matmul(Q_rotated.transpose(-1, -2), dLoss_dA) / (d_h**0.5)\n",
    "\n",
    "# Step 5: Gradient through RoPE\n",
    "dLoss_dK_transposed = dLoss_dK_rotated * cos - rotate_half(dLoss_dK_rotated) * sin\n",
    "\n",
    "# Step 6: Reshape and compute gradient for W_K\n",
    "dLoss_dK = dLoss_dK_transposed.transpose(1, 2).reshape(B, S, H * d_h)\n",
    "manual_grad_W_K = torch.einsum('bsd,bse->de', X.detach(), dLoss_dK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0192,  0.0048],\n",
       "        [-0.0047, -0.0012]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_K.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0158, -0.0219],\n",
       "        [-0.0039,  0.0152]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_grad_W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0118, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(manual_grad_W_K - W_K.grad).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3479,  0.4229],\n",
       "        [ 0.3712, -0.2417]], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3951, -1.1592],\n",
       "         [ 0.0997,  0.1972]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected\n",
    "```\n",
    "Q = tensor([[[-0.3950, -1.1592],\n",
    "            [ 0.0996,  0.1973]]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0076, -0.1648],\n",
       "         [ 0.1887,  0.0459]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "K = tensor([[[-1.0079, -0.1645],\n",
    "            [ 0.1888,  0.0460]]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.0076, -0.1648],\n",
       "          [ 0.1887,  0.0459]]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_transposed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected\n",
    "```\n",
    "tensor([[[[-1.0079, -0.1645],\n",
    "          [ 0.1888,  0.0460]]]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000],\n",
       "          [0.8415, 0.8415]]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.7708,  0.6129],\n",
       "          [ 0.0000,  0.0000]]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dLoss_dO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected\n",
    "```\n",
    "tensor([[[[ 0.7708, -0.6129],\n",
    "          [ 0.0000,  0.0000]]]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2880, -1.0236],\n",
       "          [-0.0507,  0.2050]]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_transposed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected\n",
    "```\n",
    "tensor([[[[ 0.2881, -1.0241],\n",
    "          [-0.0508,  0.2050]]]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dLoss_dA_before_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdLoss_dA_before_mask\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'dLoss_dA_before_mask' is not defined"
     ]
    }
   ],
   "source": [
    "dLoss_dA_before_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
